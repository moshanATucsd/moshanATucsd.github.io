---
layout: publication
title: Mo Shan - Publication
description: Mo Shan's publication
category: publication
---

<section>
<h2>Journal Papers</h2>
<div class="spacer"></div>

    <section>
      <div>

        <p>
        <img style="float: left; margin: 0px 15px 15px 0px;" src="/images/publication/jocch_overview.png" alt="Oxford Screenshot" width="280" align="middle" hspace="20">
        </p>

        <p>
        Zhi Gao, <strong>Mo Shan</strong>, and Qingquan Li.
        Adaptive sparse representation for analyzing artistic style of paintings.
        Journal on Computing and Cultural Heritage (JOCCH) 8.4 (2015): 22.
        </p>

        <p>
        <a href="http://dl.acm.org/citation.cfm?id=2756556">[Paper]</a>
        </p>

      </div>
    </section>

</section>
<div class="spacer"></div>

<section>
<h2>Conference Papers</h2>

<section>
<div class="spacer"></div>
    <section>
    <div>
        <p>
        <img style="float: left; margin: 0px 15px 15px 0px;" src="/images/publication/orcvio_overview.png" alt="Oxford Screenshot" width="280" align="middle" hspace="20">
        </p>

        <p>
        <strong>M. Shan</strong>, Q. Feng, N. Atanasov. (2020). OrcVIO: Object residual constrained Visual-Inertial Odometry.
        In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Las Vegas.
        </p>

        <p>
        <a href="https://moshanatucsd.github.io/orcvio_githubpage/">[Project]</a>
        <a href="https://arxiv.org/abs/2007.15107">[Paper]</a>
        <a href="https://www.youtube.com/watch?v=CRDSB-SYFhQ&feature=youtu.be">[Demo video]</a>
        <a href="https://docs.google.com/presentation/d/12nX-SHC_ZR3yoyOscBn3ZU_Oqsk0jpolGdX7IH7HKM8/edit?usp=sharing">[Slides]</a>
        <a href="https://github.com/moshanATucsd/orcvio_python_opensource">[Code]</a>
        </p>
    </div>
    </section>
</section>

<section>
<div class="spacer"></div>
    <section>
    <div>
        <p>
        <img style="float: left; margin: 0px 15px 15px 0px;" src="/images/publication/iros_2019.png" alt="Oxford Screenshot" width="280" align="middle" hspace="20">
        </p>

        <p>
        Q. Feng, Y. Meng, <strong>M. Shan</strong>, N. Atanasov. (2019). Localization and Mapping using Instance-specific Mesh Models.
        In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Macau.
        </p>

        <p>
        <a href="https://fengqiaojun.github.io/paper/Feng_DeformableMeshModel_IROS19.pdf">[Paper]</a>
        <a href="http://acsweb.ucsd.edu/~qif007/IROS19_InstanceMesh.html">[Project]</a>
        </p>
    </div>
    </section>
</section>

<section>
<div class="spacer"></div>
    <section>
    <div>
        <p>
        <img style="float: left; margin: 0px 15px 15px 0px;" src="/images/publication/scr2019_overview.png" alt="Oxford Screenshot" width="280" align="middle" hspace="20">
        </p>

        <p>
        <strong>Mo Shan</strong>, (2019). Weakly supervised keypoint detection.
        SoCal Robotics Symposium, Caltech.
        </p>

        <p>
        <a href="https://www.researchgate.net/publication/332511547_Weakly_supervised_keypoint_detection">[Paper]</a>
        <a href="/pdfs/poster/scr2019_poster.pdf">[Poster]</a>
        <a href="https://github.com/moshanATucsd/weakly_supervised_keypoint_detection">[Code]</a>
        </p>
    </div>
    </section>
</section>

<section>
<div class="spacer"></div>
    <section>
    <div>
        <p>
        <img style="float: left; margin: 0px 15px 15px 0px;" src="/images/publication/rss2017_overview.png" alt="Oxford Screenshot" width="280" align="middle" hspace="20">
        </p>

        <p>
        <strong>Mo Shan</strong>, Nikolay Atanasov. (2017).
        A spatiotemporal model with visual attention for video classification. In
        Robotics: Science and Systems 2017 Workshop on Articulated Model Tracking.
        </p>

        <p>
        <a href="https://arxiv.org/abs/1707.02069">[Paper]</a>
        <a href="/pdfs/poster/A spatiotemporal model with visual attention for video classification.pdf">[Poster]</a>
        <a href="/pdfs/presentation/A spatiotemporal model with visual attention for video classification.pdf">[Slides]</a>
        <a href="https://github.com/moshanATucsd/A-spatiotemporal-model-with-visual-attention-for-video-classification">[Code]</a>
        </p>
    </div>
    </section>
</section>

<section>
<div class="spacer"></div>
    <section>
        <div>
            <p>
            <img style="float: left; margin: 0px 15px 15px 0px;" src="/images/publication/robio15_overview.png" alt="Oxford Screenshot" width="280" align="middle" hspace="20">
            </p>

            <p>
            <strong>Mo Shan</strong>, Fei Wang, Feng Lin, Zhi Gao, Ya Z. Tang, Ben M. Chen. (2015).
            Google Map Aided Visual Navigation for UAVs in GPS-denied Environment. In
            IEEE International Conference on Robotics and Biomimetics (ROBIO). Zhuhai, China.
            </p>

            <p>
            <a href="https://arxiv.org/abs/1703.10125">[Paper]</a>
            <a href="/pdfs/poster/Google Map Aided Visual Navigation for UAVs in GPS-denied Environment.pdf">[Poster]</a>
            <a href="https://www.youtube.com/watch?v=WYoQgMS792Y">[Oral presentation]</a>
            <a href="/pdfs/presentation/HOP Robio2015 Presentation Shan Mo.pdf">[Slides]</a>
            <a href="https://www.youtube.com/watch?v=nGkQ-aSxugM">[Demo video]</a>
            <a href="https://github.com/shanmo/IMAV2014-Dataset">[Dataset]</a>
            <a href="https://goo.gl/ZqBDLL">[PaoPao Robot Talk]</a>
            <a href="https://moshanatucsd.github.io//blog/geo-ref-qa.html">[Talk Q&A]</a>
            <a href="/pdfs/presentation/Geo-referenced UAV Localization.pdf">[Talk Slides]</a>
            <a href="https://www.researchgate.net/publication/342078399_Google_Map_Oriented_Robust_Visual_Navigation_for_MAVs_in_GPS-denied_Environment?channel=doi&linkId=5ee0f25c92851cf1386f6f30&showFulltext=true">[Preprint]</a>
            </p>
        </div>
    </section>
</section>

<section>
<div class="spacer"></div>
    <section>
        <div>
            <p>
            <img style="float: left; margin: 0px 15px 15px 0px;" src="/images/publication/eccv_overview.png" alt="Oxford Screenshot" width="280" align="middle" hspace="20">
            </p>

            <p>
            Zhi Gao, Loong-Fah Cheong, and <strong>Mo Shan</strong>.
            Block-sparse RPCA for consistent foreground detection.
            Computer Visionâ€“ECCV 2012 (2012): 690-703.
            </p>

            <p>
            <a href="https://www.ece.nus.edu.sg/stfpage/eleclf/Block-sparse%20RPCA%20for%20Consistent%20Foregroud%20Detection.pdf">[Paper]</a>
            </p>
        </div>
    </section>
</section>


</section>
